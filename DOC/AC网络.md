# Actor-Critic网络

​		PG算法需要完成整个游戏过程，直到最终状态，才能通过回溯计算G值。这使得PG方法的效率被限制。为了克服这个缺点可以使用TD（时许差分），但是有一个问题，G值如何计算？

# 解决办法

使用两个神经网络

**Actor**：输入状态S，输出策略，负责选择动作

**Critic**：输入状态S，输出每个动作的评分